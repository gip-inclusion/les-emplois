# Generated by Django 5.0.6 on 2024-05-31 08:08

import time

from django.db import migrations
from django.db.models import Case, DateTimeField, F, OuterRef, Subquery, When
from django.db.models.functions import Coalesce

from itou.approvals.enums import Origin
from itou.job_applications.enums import JobApplicationState
from itou.job_applications.models import JobApplicationWorkflow
from itou.utils.iterators import chunks


def _fill_accepted_jobapplication_processed_at(apps, schema_editor):
    JobApplication = apps.get_model("job_applications", "JobApplication")
    JobApplicationTransitionLog = apps.get_model("job_applications", "JobApplicationTransitionLog")

    created_at_from_transition = Subquery(
        JobApplicationTransitionLog.objects.filter(
            job_application=OuterRef("pk"),
            transition=JobApplicationWorkflow.TRANSITION_ACCEPT,
        )
        .order_by("-timestamp")
        .values("timestamp")[:1],
    )

    accepted_qs = (
        JobApplication.objects.filter(state=JobApplicationState.ACCEPTED)
        .filter(processed_at=None)
        .annotate(
            accepted_at=Case(
                # Mega Super duper special case to handle job applications created to generate AI's Approvals
                When(
                    origin=Origin.AI_STOCK,
                    then=F("hiring_start_at"),
                ),
                When(origin=Origin.PE_APPROVAL, then=F("created_at")),
                When(
                    state=JobApplicationState.ACCEPTED,
                    # A job_application created at the accepted status will
                    # not have transitions logs, fallback on created_at
                    then=Coalesce(created_at_from_transition, F("created_at")),
                ),
                default=created_at_from_transition,
                output_field=DateTimeField(),
            )
        )
    )
    job_apps_ids = list(
        JobApplication.objects.filter(state=JobApplicationState.ACCEPTED)
        .filter(processed_at=None)
        .values_list("pk", flat=True)
    )

    count = 0
    start = time.perf_counter()
    print(f"Updating {len(job_apps_ids)} accepted job applications")
    for ids in chunks(job_apps_ids, 10000):
        job_applications = list(accepted_qs.filter(pk__in=ids))
        for job_application in job_applications:
            job_application.processed_at = job_application.accepted_at
        count += JobApplication.objects.bulk_update(job_applications, {"processed_at"})
        print(f"{count} accepted job applications migrated in {time.perf_counter() - start:.2f} sec")


def _fill_refused_jobapplication_processed_at(apps, schema_editor):
    JobApplication = apps.get_model("job_applications", "JobApplication")
    JobApplicationTransitionLog = apps.get_model("job_applications", "JobApplicationTransitionLog")
    refused_qs = (
        JobApplication.objects.filter(state=JobApplicationState.REFUSED)
        .filter(processed_at=None)
        .annotate(
            refused_at=Subquery(
                JobApplicationTransitionLog.objects.filter(
                    job_application=OuterRef("pk"),
                    transition=JobApplicationWorkflow.TRANSITION_REFUSE,
                )
                .order_by("-timestamp")
                .values("timestamp")[:1],
            )
        )
    )
    job_apps_ids = list(
        JobApplication.objects.filter(state=JobApplicationState.REFUSED)
        .filter(processed_at=None)
        .values_list("pk", flat=True)
    )

    count = 0
    start = time.perf_counter()
    print(f"Updating {len(job_apps_ids)} refused job applications")
    for ids in chunks(job_apps_ids, 10000):
        job_applications = list(refused_qs.filter(pk__in=ids))
        for job_application in job_applications:
            job_application.processed_at = job_application.refused_at or job_application.updated_at
        count += JobApplication.objects.bulk_update(job_applications, {"processed_at"})
        print(f"{count} refused job applications migrated in {time.perf_counter() - start:.2f} sec")


def _fill_cancelled_jobapplication_processed_at(apps, schema_editor):
    JobApplication = apps.get_model("job_applications", "JobApplication")
    JobApplicationTransitionLog = apps.get_model("job_applications", "JobApplicationTransitionLog")
    cancelled_qs = (
        JobApplication.objects.filter(state=JobApplicationState.CANCELLED)
        .filter(processed_at=None)
        .annotate(
            cancelled_at=Subquery(
                JobApplicationTransitionLog.objects.filter(
                    job_application=OuterRef("pk"),
                    transition=JobApplicationWorkflow.TRANSITION_CANCEL,
                )
                .order_by("-timestamp")
                .values("timestamp")[:1],
            )
        )
    )
    job_apps_ids = list(
        JobApplication.objects.filter(state=JobApplicationState.CANCELLED)
        .filter(processed_at=None)
        .values_list("pk", flat=True)
    )

    count = 0
    start = time.perf_counter()
    print(f"Updating {len(job_apps_ids)} cancelled job applications")
    for ids in chunks(job_apps_ids, 10000):
        job_applications = list(cancelled_qs.filter(pk__in=ids))
        for job_application in job_applications:
            job_application.processed_at = job_application.cancelled_at or job_application.updated_at
        count += JobApplication.objects.bulk_update(job_applications, {"processed_at"})
        print(f"{count} cancelled job applications migrated in {time.perf_counter() - start:.2f} sec")


def _fill_obsolete_jobapplication_processed_at(apps, schema_editor):
    JobApplication = apps.get_model("job_applications", "JobApplication")
    JobApplicationTransitionLog = apps.get_model("job_applications", "JobApplicationTransitionLog")
    obsolete_qs = (
        JobApplication.objects.filter(state=JobApplicationState.OBSOLETE)
        .filter(processed_at=None)
        .annotate(
            obsolete_at=Subquery(
                JobApplicationTransitionLog.objects.filter(
                    job_application=OuterRef("pk"),
                    transition=JobApplicationWorkflow.TRANSITION_RENDER_OBSOLETE,
                )
                .order_by("-timestamp")
                .values("timestamp")[:1],
            )
        )
    )
    job_apps_ids = list(
        JobApplication.objects.filter(state=JobApplicationState.OBSOLETE)
        .filter(processed_at=None)
        .values_list("pk", flat=True)
    )

    count = 0
    start = time.perf_counter()
    print(f"Updating {len(job_apps_ids)} obsolete job applications")
    for ids in chunks(job_apps_ids, 10000):
        job_applications = list(obsolete_qs.filter(pk__in=ids))
        for job_application in job_applications:
            job_application.processed_at = job_application.obsolete_at or job_application.updated_at
        count += JobApplication.objects.bulk_update(job_applications, {"processed_at"})
        print(f"{count} obsolete job applications migrated in {time.perf_counter() - start:.2f} sec")


class Migration(migrations.Migration):
    atomic = False

    dependencies = [
        ("job_applications", "0004_jobapplication_processed_at"),
    ]

    operations = [
        migrations.RunPython(_fill_obsolete_jobapplication_processed_at, migrations.RunPython.noop, elidable=True),
        migrations.RunPython(_fill_cancelled_jobapplication_processed_at, migrations.RunPython.noop, elidable=True),
        migrations.RunPython(_fill_accepted_jobapplication_processed_at, migrations.RunPython.noop, elidable=True),
        migrations.RunPython(_fill_refused_jobapplication_processed_at, migrations.RunPython.noop, elidable=True),
    ]
